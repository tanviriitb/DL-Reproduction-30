{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install neurobench\n\nimport copy\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, ConcatDataset\n\nfrom neurobench.benchmarks import Benchmark\nfrom neurobench.datasets import MSWC\nfrom neurobench.datasets.MSWC_IncrementalLoader import IncrementalFewShot\nfrom tqdm import tqdm\n\n!pip install --force-reinstall --no-deps git+https://github.com/tanviriitb/TCN-library.git@global-pool\n!pip install torchsummary\n!pip install -U numpy\n\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-04-02T11:41:55.189609Z","iopub.execute_input":"2024-04-02T11:41:55.190064Z","iopub.status.idle":"2024-04-02T11:43:02.388643Z","shell.execute_reply.started":"2024-04-02T11:41:55.190031Z","shell.execute_reply":"2024-04-02T11:43:02.387101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data in repo root dir\nROOT = \"./data/\"\n\ndirectory = \"./model_data\"\n\nif not os.path.exists(directory):\n        try:\n            os.makedirs(directory)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n\nNUM_WORKERS = 4\nBATCH_SIZE = 256","metadata":{"execution":{"iopub.status.busy":"2024-04-02T11:43:20.830691Z","iopub.execute_input":"2024-04-02T11:43:20.831708Z","iopub.status.idle":"2024-04-02T11:43:20.837294Z","shell.execute_reply.started":"2024-04-02T11:43:20.831663Z","shell.execute_reply":"2024-04-02T11:43:20.836229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif device == torch.device(\"cuda\"):\n    PIN_MEMORY = True\nelse:\n    PIN_MEMORY = False\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-02T11:43:24.273855Z","iopub.execute_input":"2024-04-02T11:43:24.274215Z","iopub.status.idle":"2024-04-02T11:43:24.282539Z","shell.execute_reply.started":"2024-04-02T11:43:24.274189Z","shell.execute_reply":"2024-04-02T11:43:24.281477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPIKING = False","metadata":{"execution":{"iopub.status.busy":"2024-04-02T11:43:26.836771Z","iopub.execute_input":"2024-04-02T11:43:26.837206Z","iopub.status.idle":"2024-04-02T11:43:26.843337Z","shell.execute_reply.started":"2024-04-02T11:43:26.837172Z","shell.execute_reply":"2024-04-02T11:43:26.841881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from neurobench.preprocessing import MFCCPreProcessor, S2SPreProcessor\n\nn_fft = 512\nwin_length = None\nhop_length = 240\nn_mels = 20\nn_mfcc = 20\n\nif SPIKING:\n    encode = S2SPreProcessor(device, transpose=True)\n    config_change = {\"sample_rate\": 48000,\n                     \"hop_length\": 240}\n    encode.configure(threshold=1.0, **config_change)\nelse:\n    encode = MFCCPreProcessor(\n        sample_rate=48000,\n        n_mfcc=n_mfcc,\n        melkwargs={\n            \"n_fft\": n_fft,\n            \"n_mels\": n_mels,\n            \"hop_length\": hop_length,\n            \"mel_scale\": \"htk\",\n            \"f_min\": 20,\n            \"f_max\": 4000,\n        },\n        device = device\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-01T14:58:25.035269Z","iopub.execute_input":"2024-04-01T14:58:25.035570Z","iopub.status.idle":"2024-04-01T14:58:25.048141Z","shell.execute_reply.started":"2024-04-01T14:58:25.035547Z","shell.execute_reply":"2024-04-01T14:58:25.047228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_train_set = MSWC(root=ROOT, subset=\"base\", procedure=\"training\")\n\ntrain_loader = DataLoader(base_train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n\nbase_validation_set = MSWC(root=ROOT, subset=\"base\", procedure=\"validation\")\n\nvalidation_loader = DataLoader(base_validation_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T14:58:25.049072Z","iopub.execute_input":"2024-04-01T14:58:25.050423Z","iopub.status.idle":"2024-04-01T14:58:25.190667Z","shell.execute_reply.started":"2024-04-01T14:58:25.050397Z","shell.execute_reply":"2024-04-01T14:58:25.189781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tcn_lib import TCN\nfrom torchsummary import summary\n\nfeature_count = 128\nmodel = TCN(20, 200, [64] * 2 + [128] * 2, [9] * 4, batch_norm=True, weight_norm=True, \n            residual=True, bottleneck=True, groups=32, dropout = 0.2).to(device)\n\nsummary(model, (20, 200))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T11:44:09.744152Z","iopub.execute_input":"2024-04-02T11:44:09.744600Z","iopub.status.idle":"2024-04-02T11:44:09.796744Z","shell.execute_reply.started":"2024-04-02T11:44:09.744564Z","shell.execute_reply":"2024-04-02T11:44:09.795455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SaveBestModel:\n    \"\"\"\n    Class to save the best model while training. If the current epoch's \n    validation loss is less than the previous least less, then save the\n    model state.\n    \"\"\"\n    def __init__(\n        self, best_valid_loss= 100\n    ):\n        self.best_valid_loss = best_valid_loss\n        \n    def __call__(\n        self, current_valid_loss, \n        epoch, model\n    ):\n        if current_valid_loss < self.best_valid_loss:\n            self.best_valid_loss = current_valid_loss\n            print(f\"\\nLeast validation error: {self.best_valid_loss}\")\n            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n            torch.save({\n                'epoch': epoch+1,\n                'model_state_dict': model.state_dict(),\n                }, './model_data/best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-01T14:58:25.236056Z","iopub.execute_input":"2024-04-01T14:58:25.236340Z","iopub.status.idle":"2024-04-01T14:58:25.242187Z","shell.execute_reply.started":"2024-04-01T14:58:25.236317Z","shell.execute_reply":"2024-04-01T14:58:25.241275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import CosineAnnealingLR\n\n# Define your hyperparameters\nepochs = 15\nlr_max = 5e-3  # Initial maximum learning rate\nlr_min = 1e-5  # Minimum learning rate\nT_max = epochs  # Number of epochs for one cycle\n\n# Create loss function, optimizer, and learning rate scheduler\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr_max)\nlr_scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=lr_min)\nsave_best_model = SaveBestModel()\n\nfor epoch in tqdm(range(epochs)):\n    train_avg_loss = 0\n    train_correct = 0\n    train_total = 0\n\n    validation_avg_loss = 0\n    validation_correct = 0\n    validation_total = 0\n    \n    model.train()\n\n    for data, target in train_loader:\n        data, target = encode((data.to(device), target.to(device)))\n        data = data.squeeze()\n\n        optimizer.zero_grad()\n        \n        features, output = model(data)\n\n        # Calculate Loss\n        loss = criterion(output, target)\n\n        loss.backward()\n        optimizer.step()\n\n        train_avg_loss += loss.item()\n        _, predicted = output.max(1)\n        train_total += target.size(0)\n        train_correct += predicted.eq(target).sum().item()\n\n    \n    model.eval()\n\n    with torch.no_grad():\n        for data, target in validation_loader:\n            data, target = encode((data.to(device), target.to(device)))\n            data = data.squeeze()\n\n            _, output = model(data)\n            loss = criterion(output, target)\n\n            validation_avg_loss += loss.item()\n            _, predicted = output.max(1)\n            validation_total += target.size(0)\n            validation_correct += predicted.eq(target).sum().item()\n\n    train_loss, train_acc = train_avg_loss / len(train_loader), 100 * train_correct / train_total\n    validation_loss, validation_acc = validation_avg_loss / len(validation_loader), 100 * validation_correct / validation_total\n\n    print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}\")\n    print(f\"Epoch {epoch} - Validation Loss: {validation_loss:.4f} - Validation Acc: {validation_acc:.2f}\")\n\n    save_best_model(\n        validation_loss, epoch, model\n    )\n    \n    # Step the scheduler\n    lr_scheduler.step()\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:44:07.910354Z","iopub.execute_input":"2024-04-01T16:44:07.910696Z","iopub.status.idle":"2024-04-01T16:48:54.170828Z","shell.execute_reply.started":"2024-04-01T16:44:07.910669Z","shell.execute_reply":"2024-04-01T16:48:54.169372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}