{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:02.314558Z","iopub.status.busy":"2024-03-24T01:43:02.313396Z","iopub.status.idle":"2024-03-24T01:43:03.527873Z","shell.execute_reply":"2024-03-24T01:43:03.526495Z","shell.execute_reply.started":"2024-03-24T01:43:02.314510Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["^C\n","Fatal Python error: init_import_site: Failed to import the site module\n","Python runtime state: initialized\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site.py\", line 617, in <module>\n","    main()\n","  File \"/opt/conda/lib/python3.10/site.py\", line 610, in main\n","    execsitecustomize()\n","  File \"/opt/conda/lib/python3.10/site.py\", line 549, in execsitecustomize\n","    import sitecustomize\n","  File \"/root/.local/lib/python3.10/site-packages/sitecustomize.py\", line 3, in <module>\n","    from log import Log\n","  File \"/root/.local/lib/python3.10/site-packages/log.py\", line 5, in <module>\n","    import google.auth\n","  File \"/opt/conda/lib/python3.10/site-packages/google/auth/__init__.py\", line 22, in <module>\n","    from google.auth._default import (\n","  File \"/opt/conda/lib/python3.10/site-packages/google/auth/_default.py\", line 28, in <module>\n","    import google.auth.transport._http_client\n","  File \"/opt/conda/lib/python3.10/site-packages/google/auth/transport/__init__.py\", line 28, in <module>\n","    import http.client as http_client\n","  File \"/opt/conda/lib/python3.10/http/client.py\", line 71, in <module>\n","    import email.parser\n","  File \"/opt/conda/lib/python3.10/email/parser.py\", line 12, in <module>\n","    from email.feedparser import FeedParser, BytesFeedParser\n","  File \"/opt/conda/lib/python3.10/email/feedparser.py\", line 27, in <module>\n","    from email._policybase import compat32\n","  File \"/opt/conda/lib/python3.10/email/_policybase.py\", line 9, in <module>\n","    from email.utils import _has_surrogates\n","  File \"/opt/conda/lib/python3.10/email/utils.py\", line 29, in <module>\n","    import socket\n","  File \"/opt/conda/lib/python3.10/socket.py\", line 80, in <module>\n","    IntEnum._convert_(\n","  File \"/opt/conda/lib/python3.10/enum.py\", line 563, in _convert_\n","    cls = cls(name, members, module=module)\n","  File \"/opt/conda/lib/python3.10/enum.py\", line 387, in __call__\n","    return cls._create_(\n","  File \"/opt/conda/lib/python3.10/enum.py\", line 517, in _create_\n","    classdict[member_name] = member_value\n","  File \"/opt/conda/lib/python3.10/enum.py\", line 137, in __setitem__\n","    elif not _is_descriptor(value):\n","  File \"/opt/conda/lib/python3.10/enum.py\", line 17, in _is_descriptor\n","    hasattr(obj, '__get__') or\n","KeyboardInterrupt\n"]}],"source":["!pip install neurobench\n","\n","import copy\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, ConcatDataset\n","\n","from neurobench.benchmarks import Benchmark\n","from neurobench.datasets import MSWC\n","from neurobench.datasets.MSWC_IncrementalLoader import IncrementalFewShot\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:03.530848Z","iopub.status.busy":"2024-03-24T01:43:03.530072Z","iopub.status.idle":"2024-03-24T01:43:09.555222Z","shell.execute_reply":"2024-03-24T01:43:09.554035Z","shell.execute_reply.started":"2024-03-24T01:43:03.530808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]},{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-17e21288a0afc628\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-17e21288a0afc628\");\n","          const url = new URL(\"/\", window.location);\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext tensorboard\n","# train and collect logs then call tensorboard\n","%tensorboard --logdir runs/"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.556867Z","iopub.status.busy":"2024-03-24T01:43:09.556431Z","iopub.status.idle":"2024-03-24T01:43:09.561685Z","shell.execute_reply":"2024-03-24T01:43:09.560522Z","shell.execute_reply.started":"2024-03-24T01:43:09.556828Z"},"trusted":true},"outputs":[],"source":["# To completely clean your tensorboard uncomment and run the following command.\n","#!rm -r runs"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.565695Z","iopub.status.busy":"2024-03-24T01:43:09.564979Z","iopub.status.idle":"2024-03-24T01:43:09.574501Z","shell.execute_reply":"2024-03-24T01:43:09.573419Z","shell.execute_reply.started":"2024-03-24T01:43:09.565652Z"},"trusted":true},"outputs":[],"source":["# data in repo root dir\n","ROOT = \"./data/\"\n","\n","NUM_WORKERS = 4\n","BATCH_SIZE = 256"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.576482Z","iopub.status.busy":"2024-03-24T01:43:09.575941Z","iopub.status.idle":"2024-03-24T01:43:09.589889Z","shell.execute_reply":"2024-03-24T01:43:09.588725Z","shell.execute_reply.started":"2024-03-24T01:43:09.576451Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if device == torch.device(\"cuda\"):\n","    PIN_MEMORY = True\n","else:\n","    PIN_MEMORY = False\n","device"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.592286Z","iopub.status.busy":"2024-03-24T01:43:09.591206Z","iopub.status.idle":"2024-03-24T01:43:09.600563Z","shell.execute_reply":"2024-03-24T01:43:09.599332Z","shell.execute_reply.started":"2024-03-24T01:43:09.592251Z"},"trusted":true},"outputs":[],"source":["SPIKING = False"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.602492Z","iopub.status.busy":"2024-03-24T01:43:09.602132Z","iopub.status.idle":"2024-03-24T01:43:09.616014Z","shell.execute_reply":"2024-03-24T01:43:09.614845Z","shell.execute_reply.started":"2024-03-24T01:43:09.602462Z"},"trusted":true},"outputs":[],"source":["from neurobench.preprocessing import MFCCPreProcessor, S2SPreProcessor\n","\n","n_fft = 512\n","win_length = None\n","hop_length = 240\n","n_mels = 20\n","n_mfcc = 20\n","\n","if SPIKING:\n","    encode = S2SPreProcessor(device, transpose=True)\n","    config_change = {\"sample_rate\": 48000,\n","                     \"hop_length\": 240}\n","    encode.configure(threshold=1.0, **config_change)\n","else:\n","    encode = MFCCPreProcessor(\n","        sample_rate=48000,\n","        n_mfcc=n_mfcc,\n","        melkwargs={\n","            \"n_fft\": n_fft,\n","            \"n_mels\": n_mels,\n","            \"hop_length\": hop_length,\n","            \"mel_scale\": \"htk\",\n","            \"f_min\": 20,\n","            \"f_max\": 4000,\n","        },\n","        device = device\n","    )"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:09.618411Z","iopub.status.busy":"2024-03-24T01:43:09.617790Z","iopub.status.idle":"2024-03-24T01:43:09.791950Z","shell.execute_reply":"2024-03-24T01:43:09.790870Z","shell.execute_reply.started":"2024-03-24T01:43:09.618380Z"},"trusted":true},"outputs":[],"source":["base_train_set = MSWC(root=ROOT, subset=\"base\", procedure=\"training\")\n","\n","train_loader = DataLoader(base_train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n","\n","base_validation_set = MSWC(root=ROOT, subset=\"base\", procedure=\"validation\")\n","\n","validation_loader = DataLoader(base_validation_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:51:49.168932Z","iopub.status.busy":"2024-03-24T01:51:49.168356Z","iopub.status.idle":"2024-03-24T01:52:22.096056Z","shell.execute_reply":"2024-03-24T01:52:22.094641Z","shell.execute_reply.started":"2024-03-24T01:51:49.168884Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting git+https://github.com/V0XNIHILI/TCN-library.git\n","  Cloning https://github.com/V0XNIHILI/TCN-library.git to /tmp/pip-req-build-rcbkfat5\n","  Running command git clone --filter=blob:none --quiet https://github.com/V0XNIHILI/TCN-library.git /tmp/pip-req-build-rcbkfat5\n","  Resolved https://github.com/V0XNIHILI/TCN-library.git to commit ba449992fef2f43f310ba40571e32ff080f5a064\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from tcn-library==0.0.1) (2.1.2+cpu)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->tcn-library==0.0.1) (2024.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->tcn-library==0.0.1) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->tcn-library==0.0.1) (1.3.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv1d-1              [-1, 32, 200]             640\n","       BatchNorm1d-2              [-1, 32, 200]              64\n","              ReLU-3              [-1, 32, 200]               0\n","           Dropout-4              [-1, 32, 200]               0\n","       _WeightNorm-5                 [-1, 4, 9]               0\n","ParametrizedConv1d-6              [-1, 32, 208]           1,152\n","       _WeightNorm-7                 [-1, 4, 9]               0\n","       _WeightNorm-8                 [-1, 4, 9]               0\n","       _WeightNorm-9                 [-1, 4, 9]               0\n","      _WeightNorm-10                 [-1, 4, 9]               0\n","      BatchNorm1d-11              [-1, 32, 208]              64\n","          Chomp1d-12              [-1, 32, 200]               0\n","             ReLU-13              [-1, 32, 200]               0\n","          Dropout-14              [-1, 32, 200]               0\n","           Conv1d-15              [-1, 64, 200]           2,048\n","      BatchNorm1d-16              [-1, 64, 200]             128\n","         Identity-17              [-1, 64, 200]               0\n","          Dropout-18              [-1, 64, 200]               0\n","           Conv1d-19              [-1, 64, 200]           1,280\n","      BatchNorm1d-20              [-1, 64, 200]             128\n","         Identity-21              [-1, 64, 200]               0\n","          Dropout-22              [-1, 64, 200]               0\n","             ReLU-23              [-1, 64, 200]               0\n","TemporalBottleneck-24              [-1, 64, 200]               0\n","           Conv1d-25              [-1, 32, 200]           2,048\n","      BatchNorm1d-26              [-1, 32, 200]              64\n","             ReLU-27              [-1, 32, 200]               0\n","          Dropout-28              [-1, 32, 200]               0\n","      _WeightNorm-29                 [-1, 4, 9]               0\n","ParametrizedConv1d-30              [-1, 32, 216]           1,152\n","      _WeightNorm-31                 [-1, 4, 9]               0\n","      _WeightNorm-32                 [-1, 4, 9]               0\n","      _WeightNorm-33                 [-1, 4, 9]               0\n","      _WeightNorm-34                 [-1, 4, 9]               0\n","      BatchNorm1d-35              [-1, 32, 216]              64\n","          Chomp1d-36              [-1, 32, 200]               0\n","             ReLU-37              [-1, 32, 200]               0\n","          Dropout-38              [-1, 32, 200]               0\n","           Conv1d-39              [-1, 64, 200]           2,048\n","      BatchNorm1d-40              [-1, 64, 200]             128\n","         Identity-41              [-1, 64, 200]               0\n","          Dropout-42              [-1, 64, 200]               0\n","             ReLU-43              [-1, 64, 200]               0\n","TemporalBottleneck-44              [-1, 64, 200]               0\n","           Conv1d-45              [-1, 32, 200]           2,048\n","      BatchNorm1d-46              [-1, 32, 200]              64\n","             ReLU-47              [-1, 32, 200]               0\n","          Dropout-48              [-1, 32, 200]               0\n","      _WeightNorm-49                 [-1, 4, 9]               0\n","ParametrizedConv1d-50              [-1, 32, 232]           1,152\n","      _WeightNorm-51                 [-1, 4, 9]               0\n","      _WeightNorm-52                 [-1, 4, 9]               0\n","      _WeightNorm-53                 [-1, 4, 9]               0\n","      _WeightNorm-54                 [-1, 4, 9]               0\n","      BatchNorm1d-55              [-1, 32, 232]              64\n","          Chomp1d-56              [-1, 32, 200]               0\n","             ReLU-57              [-1, 32, 200]               0\n","          Dropout-58              [-1, 32, 200]               0\n","           Conv1d-59              [-1, 64, 200]           2,048\n","      BatchNorm1d-60              [-1, 64, 200]             128\n","         Identity-61              [-1, 64, 200]               0\n","          Dropout-62              [-1, 64, 200]               0\n","             ReLU-63              [-1, 64, 200]               0\n","TemporalBottleneck-64              [-1, 64, 200]               0\n","           Conv1d-65              [-1, 64, 200]           4,096\n","      BatchNorm1d-66              [-1, 64, 200]             128\n","             ReLU-67              [-1, 64, 200]               0\n","          Dropout-68              [-1, 64, 200]               0\n","      _WeightNorm-69                 [-1, 8, 9]               0\n","ParametrizedConv1d-70              [-1, 64, 264]           4,608\n","      _WeightNorm-71                 [-1, 8, 9]               0\n","      _WeightNorm-72                 [-1, 8, 9]               0\n","      _WeightNorm-73                 [-1, 8, 9]               0\n","      _WeightNorm-74                 [-1, 8, 9]               0\n","      BatchNorm1d-75              [-1, 64, 264]             128\n","          Chomp1d-76              [-1, 64, 200]               0\n","             ReLU-77              [-1, 64, 200]               0\n","          Dropout-78              [-1, 64, 200]               0\n","           Conv1d-79             [-1, 512, 200]          32,768\n","      BatchNorm1d-80             [-1, 512, 200]           1,024\n","         Identity-81             [-1, 512, 200]               0\n","          Dropout-82             [-1, 512, 200]               0\n","           Conv1d-83             [-1, 512, 200]          32,768\n","      BatchNorm1d-84             [-1, 512, 200]           1,024\n","         Identity-85             [-1, 512, 200]               0\n","          Dropout-86             [-1, 512, 200]               0\n","             ReLU-87             [-1, 512, 200]               0\n","TemporalBottleneck-88             [-1, 512, 200]               0\n","    LastElement1d-89                  [-1, 512]               0\n","           Linear-90                  [-1, 200]         102,600\n","================================================================\n","Total params: 195,656\n","Trainable params: 195,656\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.02\n","Forward/backward pass size (MB): 12.26\n","Params size (MB): 0.75\n","Estimated Total Size (MB): 13.02\n","----------------------------------------------------------------\n"]}],"source":["!pip install git+https://github.com/V0XNIHILI/TCN-library.git\n","!pip install torchsummary\n","\n","from tcn_lib import TCN\n","from torchsummary import summary\n","\n","model = TCN(20, 200, [(32,64)] * 3 + [(64,512)], [9] * 4, batch_norm=True, weight_norm=True, bottleneck=True, groups=8).to(device)\n","\n","summary(model, (20, 200))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:42.020363Z","iopub.status.busy":"2024-03-24T01:43:42.019414Z","iopub.status.idle":"2024-03-24T01:43:52.159239Z","shell.execute_reply":"2024-03-24T01:43:52.157701Z","shell.execute_reply.started":"2024-03-24T01:43:42.020306Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","^C\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -U numpy"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T01:43:52.163178Z","iopub.status.busy":"2024-03-24T01:43:52.162232Z","iopub.status.idle":"2024-03-24T01:44:04.301595Z","shell.execute_reply":"2024-03-24T01:44:04.297617Z","shell.execute_reply.started":"2024-03-24T01:43:52.163123Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/50 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","  0%|          | 0/50 [00:11<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m train_avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch.optim as optim\n","\n","# Create a writer to write to Tensorboard\n","writer = SummaryWriter()\n","\n","# Some hyperparams\n","epochs = 25\n","#lr_decay = 1.05\n","\n","# Create loss function and optimizer and learning rate scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-2)\n","#lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: lr_decay ** epoch)\n","\n","for epoch in tqdm(range(epochs)):\n","\n","    train_avg_loss = 0\n","    train_correct = 0\n","    train_total = 0\n","\n","    validation_avg_loss = 0\n","    validation_correct = 0\n","    validation_total = 0\n","\n","    for data, target in train_loader:\n","        data, target = encode((data.to(device), target.to(device)))\n","        data = data.squeeze()\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_avg_loss += loss.item()\n","        _, predicted = output.max(1)\n","        train_total += target.size(0)\n","        train_correct += predicted.eq(target).sum().item()\n","        \n","    with torch.no_grad():\n","        for data, target in validation_loader:\n","            data, target = encode((data.to(device), target.to(device)))\n","            data = data.squeeze()\n","\n","            output = model(data)\n","            loss = criterion(output, target)\n","\n","            validation_avg_loss += loss.item()\n","            _, predicted = output.max(1)\n","            validation_total += target.size(0)\n","            validation_correct += predicted.eq(target).sum().item()\n","\n","    train_loss, train_acc = train_avg_loss/len(train_loader), 100 * train_correct / train_total\n","    validation_loss, validation_acc = validation_avg_loss/len(validation_loader), 100 * validation_correct / validation_total\n","\n","    print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}\")\n","    print(f\"Epoch {epoch} - Validation Loss: {validation_loss:.4f} - Validation Acc: {validation_acc:.2f}\")\n","\n","    writer.add_scalars(\"Loss\", {'Train': train_loss, 'Validation':validation_loss}, epoch)\n","    writer.add_scalars('Accuracy', {'Train': train_acc,'Validation':validation_acc} , epoch)\n","\n","print('Finished Training')\n","writer.flush()\n","writer.close()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
